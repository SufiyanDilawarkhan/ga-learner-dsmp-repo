### Project Overview

 **Problem Statement**

We to put your understanding of Topic Modelling into practice! We have a dataset of news headlines sourced from the reputable Australian news source ABC (Australian Broadcasting Corp.) over a period of 15 years. If we dig into the keywords, we will see all the important episodes shaping the last decade and how they evolved over time. Ex: Financial crisis, Iraq war, multiple US elections, Ecological disasters, Terrorism, famous people, Australian crimes etc. A much better way to comprehend these topics would be using topic modelling to find out relevant topics within a particular time frame.

The main goal of this problem is to leverage the power of techniques like LSA (Latent Semantic Analysis) and LDA (Latent Dirichlet Allocation) to assign topics to unseen news headlines.


The dataset includes the entire corpus of articles published by the ABC website in the given time range. With a volume of 200 articles per day and a good focus on international news, we can be fairly certain that every event of significance has been captured here. In total there are 331100 instances of data available with two columns.

The columns in this dataset are:

- publish_date: Date of publish of the news headline.
- headline_text: Headline of the news published on that particular date.


### Learnings from the project

 Doing this project helped me understand and apply the following skills:

- Text preprocessing techniques like Tokenization, Stopword removal, POS tagging etc.
- Enhance my data visualization skills.
- Topic modelling with LSA (Latent Semantic Analysis) and LDA (Latent Dirichlet Allocation).
- Using coherence score to determine the optimum number of topics.


